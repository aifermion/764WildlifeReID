{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c6b0fb1b",
   "metadata": {},
   "source": [
    "Just follow this process for the datasets you imported in wildlife_datasets.datasets.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33b951e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from prepare_data import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73842fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_functions = {\n",
    "    'FeralCatsAkl_maxim': prepare_feralcatsakl_maxim,\n",
    "    'FeralCatsAkl_HIDiff': prepare_feralcatsakl_hidiff,\n",
    "    'FeralCatsAkl_SRMNet': prepare_feralcatsakl_srmnet,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12444db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install pycocotools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bda389eb",
   "metadata": {},
   "source": [
    "# 1. Process the datasets\n",
    "**Processing includes:**\n",
    "- Resize images\n",
    "- Crop bounding boxes\n",
    "- Crop black background of segmented images\n",
    "- If multiple identities exist in one image, we crop them and split them into two images.\n",
    "\n",
    "\n",
    "**We save two sets of images:**\n",
    "- For inference with images resized to 518x518: CLIP, DINOv2, and MegaDescriptor-L-384\n",
    "- For inference with images resized to 256x256: MegaDescriptor-T-224, MegaDescriptor-S-224, MegaDescriptor-B-224, MegaDescriptor-L-224\n",
    "\n",
    "\n",
    "**Note**: Stored images were further transformed (e.g. resized to 224x224) depending on model during the inference. Inference with smaller models using the stored 518x518 images is possible but it gives slightly different results that in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf4ea61",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dataset_dir = \"../../data/processed/cropped\"\n",
    "new_root = \"../data/images/size-256\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b39d3d7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_feralcatsakl_base(size=256, root=base_dataset_dir, new_root=new_root+'/fca_base')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3948e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "fca_base_metadata_256 = pd.read_csv('/Users/fmb/GitHub/764WildlifeReID/megadescriptor/data/images/size-256/fca_base/annotations.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48be9247",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "datasets_folder = '/Users/fmb/GitHub/764WildlifeReID/data/formatted_datasets'  # Path to downloaded datasets\n",
    "\n",
    "# Create folders with images resized to 256 and 518\n",
    "for name, prepare in prepare_functions.items():\n",
    "    print(name)\n",
    "    prepare(size=256, root=f'{datasets_folder}/{name}', new_root=new_root+'/'+name)\n",
    "    # prepare(size=518, root=f'{datasets_folder}/{name}', new_root=f'images/size-518/{name}')\n",
    "\n",
    "    # Metadata should be the same\n",
    "    # metadata_256 = pd.read_csv(f'../data/images/size-256/{name}/annotations.csv', index_col=0)\n",
    "    # metadata_518 = pd.read_csv(f'images/size-518/{name}/annotations.csv', index_col=0)\n",
    "    # assert metadata_256.equals(metadata_518)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b434e",
   "metadata": {},
   "source": [
    "# 2. Create split metadata for each dataset\n",
    "**Split datasets:**\n",
    "- Closed split, images with unknown identities are discarded\n",
    "- Store the metadata for each dataset as CSV.\n",
    "- Test set for each dataset is used for evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e24e138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from wildlife_datasets import splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ddc4aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "fca_base_metadata_256 = pd.read_csv('/Users/fmb/GitHub/764WildlifeReID/megadescriptor/data/images/size-256/fca_base/annotations.csv', index_col=0)\n",
    "\n",
    "splitter = splits.ClosedSetSplit(0.8, identity_skip='unknown', seed=666)\n",
    "idx_train, idx_test = splitter.split(fca_base_metadata_256)[0]\n",
    "\n",
    "fca_base_metadata_256.loc[fca_base_metadata_256.index[idx_train], 'split'] = 'train'\n",
    "fca_base_metadata_256.loc[fca_base_metadata_256.index[idx_test], 'split'] = 'test'\n",
    "\n",
    "os.makedirs(f'../metadata/datasets/fca_base/', exist_ok=True)\n",
    "fca_base_metadata_256.to_csv(f'../metadata/datasets/fca_base/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30c20646",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in prepare_functions:\n",
    "    metadata = pd.read_csv(f'../data/images/size-256/{name}/annotations.csv', index_col=0)\n",
    "    splitter = splits.ClosedSetSplit(0.8, identity_skip='unknown', seed=666)\n",
    "    idx_train, idx_test = splitter.split(metadata)[0]\n",
    "\n",
    "    metadata.loc[metadata.index[idx_train], 'split'] = 'train'\n",
    "    metadata.loc[metadata.index[idx_test], 'split'] = 'test'\n",
    "\n",
    "    os.makedirs(f'../metadata/datasets/{name}/', exist_ok=True)\n",
    "    metadata.to_csv(f'../metadata/datasets/{name}/metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f22fb2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create dataframe with training / test set splits\n",
    "# from wildlife_datasets import splits\n",
    "# for name in prepare_functions:\n",
    "#     metadata = pd.read_csv(f'images/size-518/{name}/annotations.csv', index_col=0)\n",
    "#     splitter = splits.ClosedSetSplit(0.8, identity_skip='unknown', seed=666)\n",
    "#     idx_train, idx_test = splitter.split(metadata)[0]\n",
    "\n",
    "#     metadata.loc[metadata.index[idx_train], 'split'] = 'train'\n",
    "#     metadata.loc[metadata.index[idx_test], 'split'] = 'test'\n",
    "\n",
    "#     os.makedirs(f'metadata/datasets/{name}/', exist_ok=True)\n",
    "#     metadata.to_csv(f'metadata/datasets/{name}/metadata.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b235422",
   "metadata": {},
   "source": [
    "# 3. Create metadata for aggregated training dataset\n",
    "- Combine training sets from metadata of all datasets to single aggregated metadata\n",
    "- The aggregated training set is used for training MegaDescriptors.\n",
    "    - Adds dataset name to identity to prevent identity name collisions\n",
    "    - Adds dataset name to the image path to enable loading the aggregated dataset using `WildlifeDataset`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140f63bd",
   "metadata": {},
   "source": [
    "#### *Note:* We don't really need to aggregate any datasets in this case, since we're treating each dataset independently\n",
    "\n",
    "nevertheless, we just follow along with the process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "779efe08",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "fca_from_metadata = pd.read_csv('/Users/fmb/GitHub/764WildlifeReID/megadescriptor/metadata/datasets/fca_base/metadata.csv', index_col=0)\n",
    "\n",
    "df = fca_from_metadata.query(\"split == 'train'\").copy()\n",
    "df['dataset'] = 'fca_base'\n",
    "df['identity'] = 'fca_base' + '_' + df['identity'].astype(str)\n",
    "df['path'] = 'fca_base' + '/' + df['path']\n",
    "results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e4b18d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# results = []\n",
    "# for name in prepare_functions:\n",
    "#     metadata = pd.read_csv(f'metadata/datasets/{name}/metadata.csv', index_col=0)\n",
    "\n",
    "#     df = metadata.query(\"split == 'train'\").copy()\n",
    "#     df['dataset'] = name\n",
    "#     df['identity'] = name + '_' + df['identity'].astype(str)\n",
    "#     df['path'] = name + '/' + df['path']\n",
    "#     results.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96e2edd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_all = pd.concat(results)\n",
    "\n",
    "os.makedirs('/Users/fmb/GitHub/764WildlifeReID/megadescriptor/metadata/combined', exist_ok=True)\n",
    "combined_all.to_csv('/Users/fmb/GitHub/764WildlifeReID/megadescriptor/metadata/combined/combined_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628954ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "compsci764",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
